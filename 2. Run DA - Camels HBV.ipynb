{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cd8d85-eb4a-45d6-925a-e3e770592043",
   "metadata": {},
   "source": [
    "### Import modules and verify they work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e710a-5aa4-40f9-a1cb-151e3cddbe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569a0f2-4bea-48cc-b5a4-ca5384e368c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general eWC\n",
    "import ewatercycle\n",
    "import ewatercycle.models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1454a07-6f82-4728-87cc-f799951db83d",
   "metadata": {},
   "source": [
    "Download plugin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3463b-eedd-4f59-a542-6afd58cf6eb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install ewatercycle-HBV==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111bc65b-8299-43ba-95fd-e92df6b92707",
   "metadata": {},
   "source": [
    "#### set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66893d-b667-4fcc-a841-683f32ed2cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd()\n",
    "forcing_path = path / \"Forcing\"\n",
    "observations_path = path / \"Observations\"\n",
    "forcing_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787c692-3f9c-402b-9b48-93daeeb47926",
   "metadata": {},
   "source": [
    "#### add parameter info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbba0f-dbc0-4812-9125-79e0df831e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Array of initial storage terms - we keep these constant for now \n",
    "##              Si,  Su, Sf, Ss\n",
    "s_0 = np.array([0,  100,  0,  5])\n",
    "\n",
    "## Array of parameters min/max bounds as a reference\n",
    "##                      Imax,  Ce,  Sumax, beta,  Pmax,  T_lag,   Kf,   Ks\n",
    "p_min_initial= np.array([0,   0.2,  40,    .5,   .001,   1,     .01,  .0001])\n",
    "p_max_initial = np.array([8,    1,  800,   4,    .3,     10,    .1,   .01])\n",
    "p_names = [\"$I_{max}$\",  \"$C_e$\",  \"$Su_{max}$\", \"Î²\",  \"$P_{max}$\",  \"$T_{lag}$\",   \"$K_f$\",   \"$K_s$\"]\n",
    "S_names = [\"Interception storage\", \"Unsaturated Rootzone Storage\", \"Fastflow storage\", \"Groundwater storage\"]\n",
    "param_names = [\"Imax\",\"Ce\",  \"Sumax\", \"Beta\",  \"Pmax\",  \"Tlag\",   \"Kf\",   \"Ks\"]\n",
    "stor_names = [\"Si\", \"Su\", \"Sf\", \"Ss\"]\n",
    "\n",
    "# set initial as mean of max,min\n",
    "par_0 = (p_min_initial + p_max_initial)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aea008-87ce-4d09-8d01-f12dfe6bb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_start_date = \"1997-08-01T00:00:00Z\"\n",
    "experiment_end_date = \"2000-08-31T00:00:00Z\"\n",
    "HRU_id = 1620500\n",
    "alpha = 1.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41855c32-2650-403e-bcad-332eab6c1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewatercycle_HBV.forcing import HBVForcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e4f93-a69a-4d20-8844-92deea52fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: get alpha correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6249ec9f-8ff2-4181-ac6f-cac309d8cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_forcing = HBVForcing(start_time = experiment_start_date,\n",
    "                          end_time = experiment_end_date,\n",
    "                          directory = forcing_path,\n",
    "                          forcing_file = f'0{HRU_id}_lump_cida_forcing_leap.txt',\n",
    "                          alpha = alpha\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5962203-87d3-45dc-acf8-1354522e5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = test_forcing.from_camels_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0dd2de-81a6-42c4-ba27-d315542403c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91871cc-ae40-44c2-97a6-b149a899423d",
   "metadata": {},
   "source": [
    "#### import observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788bf40-4cc4-45b4-b999-ffbe4f25cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = observations_path / f'0{HRU_id}_streamflow_qc.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f884c9d-a19b-4d21-8686-1abb1017fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubic_ft_to_cubic_m = 0.0283168466 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb63f5-c1a9-4485-b96a-aa3762f1bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_header = ['GAGEID','Year','Month', 'Day', 'Streamflow(cubic feet per second)','QC_flag']\n",
    "new_header_dict = dict(list(zip(range(len(new_header)),new_header)))\n",
    "\n",
    "df_Q = pd.read_fwf(observations,delimiter=' ',encoding='utf-8',header=None)\n",
    "df_Q = df_Q.rename(columns=new_header_dict)\n",
    "df_Q['Streamflow(cubic feet per second)'] = df_Q['Streamflow(cubic feet per second)'].apply(lambda x: np.nan if x==-999.00 else x)\n",
    "df_Q['Q (m3/s)'] = df_Q['Streamflow(cubic feet per second)'] * cubic_ft_to_cubic_m\n",
    "df_Q['Q'] = df_Q['Q (m3/s)'] / ds.attrs['area basin(m^2)'] * 3600 * 24 * 1000 # m3/s -> m/s ->m/d -> mm/d\n",
    "df_Q.index = df_Q.apply(lambda x: pd.Timestamp(f'{int(x.Year)}-{int(x.Month)}-{int(x.Day)}'),axis=1)\n",
    "df_Q.index.name = \"time\"\n",
    "df_Q.drop(columns=['Year','Month', 'Day','Streamflow(cubic feet per second)'],inplace=True)\n",
    "df_Q = df_Q.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82f9cf-e1b3-46ff-bd62-621b33863b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470add53-a8b1-45f2-a84f-2b06b6ea37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Q['Q'].plot()\n",
    "ax.set_xlim((pd.Timestamp('1997-08-01'),pd.Timestamp('1998-06-01')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944e1b8-e225-483d-b39e-74ed4dea37cf",
   "metadata": {},
   "source": [
    "#### import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a3c69-953c-403b-a259-125aa8370dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewatercycle.models import HBV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd67cd-b327-475a-9315-0f199c317718",
   "metadata": {},
   "source": [
    "# run DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3009b-27fa-4174-9e1f-f6aa79572962",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e4a20-0a8c-497e-9301-c38ebe57c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rng = np.random.default_rng() # Initiate a Random Number Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f410ac41-48a8-4232-bde8-957e94783852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ensemble(n_particles):\n",
    "    # for initial run sample a set of parameters - start with simpel linear random:  min+[0,1] * (max-min) -> easily changes after\n",
    "    array_random_num = np.array([[np.random.random() for i in range(len(p_max_initial))] for i in range(n_particles)])\n",
    "    p_intial = p_min_initial + array_random_num * (p_max_initial-p_min_initial)\n",
    "    \n",
    "    ensemble = []\n",
    "    for i in range(n_particles):\n",
    "        ensemble.append(HBV(forcing=test_forcing))\n",
    "        \n",
    "    for index, ensembleMember in enumerate(ensemble):\n",
    "        config_file, _ = ensembleMember.setup(\n",
    "                                              parameters=','.join([str(p) for p in p_intial[index]]), \n",
    "                                              initial_storage=','.join([str(s) for s in s_0]),\n",
    "                                              alpha=alpha\n",
    "                                             )\n",
    "        ensembleMember.initialize(config_file)\n",
    "        \n",
    "    return ensemble \n",
    "\n",
    "def generate_weights(Q_m_at_ts, obs):\n",
    "    \"Takes the enseble and observations and returns the posterior\"\n",
    "    prior = Q_m_at_ts # take last observation\n",
    "    innov2 = (obs - prior)\n",
    "    like_sigma = 0.05  # In [m]; so 5 mm\n",
    "    unnormalised_log_weights = scipy.stats.norm.logpdf(innov2, loc=0, scale=like_sigma)\n",
    "    normalised_weights = np.exp(unnormalised_log_weights - scipy.special.logsumexp(unnormalised_log_weights))\n",
    "    return normalised_weights\n",
    "\n",
    "def add_noise(like_sigma):\n",
    "    return rng.normal(loc=0, scale=like_sigma)   # log normal so can't go to 0 ? \n",
    "\n",
    "def calc_NSE(Qo, Qm):\n",
    "    QoAv  = np.mean(Qo)\n",
    "    ErrUp = np.sum((Qm - Qo)**2)\n",
    "    ErrDo = np.sum((Qo - QoAv)**2)\n",
    "    return 1 - (ErrUp / ErrDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744707a1-d095-458f-8a59-d4cad98b8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 30 # 50 seems max for current setup :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9b3cd-08cd-4e8e-b98e-c13979b2c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/65272764/ports-are-not-available-listen-tcp-0-0-0-0-50070-bind-an-attempt-was-made-to\n",
    "# run in cmd:\n",
    "# net stop winnat\n",
    "# net start winnat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c859e-4b52-4ed3-87ac-47face95a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #### run if fails \n",
    "# for index, ensembleMember in enumerate(ensemble):\n",
    "#     ensembleMember.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2507f-d55a-4828-9aa6-a3da9d7ac4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of ensemble members\n",
    "ensemble = setup_ensemble(n_particles)\n",
    "ref_model = ensemble[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e458a3-a255-48ae-93e5-d8102ff481c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = len(ds.time.values) - 1\n",
    "# n_timesteps  = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92804088-8dad-442b-b60b-bd68eeb41d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up arrays\n",
    "n_storage_terms = len(stor_names)\n",
    "n_param_terms = len(param_names)\n",
    "Q_m_arr = np.zeros((n_particles, n_timesteps))\n",
    "storage_terms_arr = np.zeros((n_particles, n_timesteps, n_storage_terms))\n",
    "parameter_terms_arr = np.zeros((n_particles, n_timesteps, n_param_terms))\n",
    "t_lag_max = 20 # for now? \n",
    "index_t_lag = 5 # fith parameter (base 0)\n",
    "print(f'{index_t_lag}th index is {param_names[index_t_lag]}')\n",
    "lag_vector_memory_arr = np.zeros((n_particles, n_timesteps,t_lag_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313b1f6-b54d-4d58-93fc-dec65520bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param_names)\n",
    "print(stor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d5e20-cba0-4f3f-81f7-4da3abdea7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time = []\n",
    "Q_obs_t_lst = []\n",
    "t_index = 0 \n",
    "## running for whole timeseries takes long, just do first couple of months to see inpact\n",
    "# while ref_model.time < ref_model.start_time + n_timesteps * ref_model.time_step:\n",
    "while ref_model.time < ref_model.end_time:\n",
    "    time.append(pd.Timestamp(ref_model.time_as_datetime.date()))\n",
    "\n",
    "    # run model forward\n",
    "    for m_index, ensembleMember in enumerate(ensemble):\n",
    "        ensembleMember.update()\n",
    "        # get model, storage and paramers\n",
    "        Q_m_arr[m_index, t_index] = ensembleMember.get_value(\"Q_m\")[0] # 1 observation per ensemble member - TODO: would be great to just do this in one go!\n",
    "        storage_terms_arr[m_index, t_index] = np.array([ensembleMember.get_value(storage) for storage in stor_names]).flatten().copy()\n",
    "        parameter_terms_arr[m_index, t_index] = np.array([ensembleMember.get_value(parameter) for parameter in param_names]).flatten().copy()\n",
    "\n",
    "        # get the memory vector\n",
    "        t_lag = int(parameter_terms_arr[m_index, t_index, index_t_lag])\n",
    "        lag_vector_memory_arr[m_index, t_index, :t_lag] = np.array([ensembleMember.get_value(f\"memory_vector{i}\") for i in range(t_lag)]).flatten()\n",
    "\n",
    "    # if t_index % 1 == 0:\n",
    "    ### resample\n",
    "    Q_obs = df_Q.loc[pd.Timestamp(ref_model.time_as_datetime.date()),\"Q\"] # get observed value from DF \n",
    "    Q_obs_t_lst.append(pd.Timestamp(ref_model.time_as_datetime.date()))\n",
    "    # add error to Q_obs - roughly sig^2 = (0.1 * Q_obs)^2 - clark 2008\n",
    "    likelihood = generate_weights(Q_m_arr[:,t_index], Q_obs) \n",
    "    resample_indices = random.choices(population=np.arange(n_particles),weights=likelihood, k=n_particles)\n",
    "    \n",
    "    new_parameters = parameter_terms_arr[:, t_index].copy()[resample_indices]\n",
    "    new_storage    = storage_terms_arr[:, t_index].copy()[resample_indices]\n",
    "    new_storage    = storage_terms_arr[:, t_index].copy()[resample_indices]\n",
    "    new_lag        = lag_vector_memory_arr[:,t_index].copy()[resample_indices] # dont have a way to set new lag function as of yet\n",
    "\n",
    "    ## add noise\n",
    "    ## TODO: literature to choose sigma - maybe make sigma dependant on the parameter: i.e. %age of parameter\n",
    "    sigma = 0.005 * Q_obs\n",
    "    new_parameters = np.array([np.array([max(perturbed + add_noise(sigma),1e-6) for perturbed in par]) \n",
    "                               for par in new_parameters.T]).T\n",
    "    new_storage    = np.array([np.array([max(perturbed + add_noise(sigma),1e-6) for perturbed in stor]) \n",
    "                               for stor in new_storage.T]).T\n",
    "\n",
    "    # new_lag        = np.array([np.array([max(perturbed + add_noise(sigma),1e-6) for perturbed in lag]) \n",
    "    #                            for lag in new_lag.T]).T\n",
    "\n",
    "    \n",
    "    #3 hard fix to get tlag to always be >= 1 ### should be fixed ewatercycle-hbv>1.2.0\n",
    "    # new_parameters[:,5] = np.array([max(1,round(par)) for par in new_parameters[:,5]])\n",
    "    \n",
    "    \n",
    "    # update the parameters & states\n",
    "    for index, ensembleMember in enumerate(ensemble):\n",
    "        # TODO: adjust so that tLag cant go to 0\n",
    "        [ensembleMember.set_value(parameter, np.array([new_parameters[index, p_index]])) for p_index, parameter in enumerate(param_names)]\n",
    "        [ensembleMember.set_value(storage, np.array([new_storage[index, s_index]])) for s_index, storage in enumerate(stor_names)]\n",
    "        new_tlag = new_parameters[index, index_t_lag]\n",
    "        [ensembleMember.set_value(f\"memory_vector{mem_index}\", np.array([new_lag[index, mem_index]])) for mem_index in range(int(new_tlag))]\n",
    "\n",
    "    # advance the index\n",
    "    t_index+=1 \n",
    "\n",
    "## TODO: way to fix this?\n",
    "# units = {}\n",
    "# for name in stor_names + param_names:\n",
    "#     units[name] = ref_model.get_units(name)\n",
    "\n",
    "\n",
    "# end model - IMPORTANT! when working with dockers\n",
    "for index, ensembleMember in enumerate(ensemble):\n",
    "    ensembleMember.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9f321-0273-493b-8930-a260fad4da2b",
   "metadata": {},
   "source": [
    "### process the numpy data into easily acessed data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad75ed7-4d48-44d2-93af-d3b7acfa530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save, load = False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e4052-17f9-4b09-84dc-433b890d6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not load:\n",
    "#     df_ensemble = pd.DataFrame(data=Q_m_arr[:,:len(time)].T,index=time,columns=[f'particle {n}' for n in range(n_particles)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5174a-c0f0-4ab7-bcb0-8a10414d50ed",
   "metadata": {},
   "source": [
    "### process states and parameters into xarrys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95343676-2174-47aa-8e08-612b4ec4cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save? \n",
    "if save:\n",
    "    df_ensemble.to_feather(r'Output/df_ensemble.feather')\n",
    "if load:\n",
    "    df_ensemble = pd.read_feather(r'Output/df_ensemble.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cbd7a-3941-403e-9347-aaa972794f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if load:\n",
    "# TODO: obtain from model \n",
    "units= {\"Imax\":\"mm\",\n",
    "        \"Ce\": \"-\",\n",
    "        \"Sumax\": \"mm\",\n",
    "        \"Beta\": \"-\",\n",
    "        \"Pmax\": \"mm\",\n",
    "        \"Tlag\": \"d\",\n",
    "        \"Kf\": \"-\",\n",
    "        \"Ks\": \"-\",\n",
    "        \"Si\": \"mm\",\n",
    "        \"Su\": \"mm\",\n",
    "        \"Sf\": \"mm\",\n",
    "        \"Ss\": \"mm\",\n",
    "        \"Ei_dt\": \"mm/d\",\n",
    "        \"Ea_dt\": \"mm/d\",\n",
    "        \"Qs_dt\": \"mm/d\",\n",
    "        \"Qf_dt\": \"mm/d\",\n",
    "        \"Q_tot_dt\": \"mm/d\",\n",
    "        \"Q_m\": \"mm/d\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce2567-5092-4e57-b625-f2c5905e4f92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not load:\n",
    "    # combine the 3D numpy arr into one dataArray\n",
    "    storage_terms_ds = xr.DataArray(storage_terms_arr,dims=[\"EnsembleMember\",\"time\",\"storage\"],\n",
    "                                    coords=[np.arange(n_particles),df_ensemble.index,stor_names],\n",
    "                                    attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                           \"history\": f\"Storage term results from ewatercycle_HBV.model\",\n",
    "                                        \"description\":\"Moddeled storage\",\n",
    "                                             \"units\": \"mm\"})\n",
    "    \n",
    "    parameter_terms_ds = xr.DataArray(parameter_terms_arr,dims=[\"EnsembleMember\",\"time\",\"parameter\"],\n",
    "                                coords=[np.arange(n_particles),df_ensemble.index,param_names],\n",
    "                                    attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                           \"history\": f\"Storage terms results from ewatercycle_HBV.model\",})\n",
    "    \n",
    "    # even better is to combine into one Data_set_- this is most intuitive way for me - probably more ways\n",
    "    data_vars = {}\n",
    "    for i, name in enumerate(stor_names):\n",
    "        storage_terms_i = xr.DataArray(storage_terms_arr[:,:,i],\n",
    "                                       name=name,\n",
    "                                       dims=[\"EnsembleMember\",\"time\"],\n",
    "                                      coords=[np.arange(n_particles),df_ensemble.index],\n",
    "                                      attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                               \"history\": f\"Storage term results from ewatercycle_HBV.model\",\n",
    "                                            \"description\":\"Moddeled storage\",\n",
    "                                                 \"units\": \"mm\"})\n",
    "        data_vars[name] = storage_terms_i\n",
    "    for i, name in enumerate(param_names):\n",
    "        storage_terms_i = xr.DataArray(parameter_terms_arr[:,:,i],\n",
    "                                       name=name,\n",
    "                                       dims=[\"EnsembleMember\",\"time\"],\n",
    "                                      coords=[np.arange(n_particles),df_ensemble.index],\n",
    "                                      attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                               \"history\": f\"Storage term results from ewatercycle_HBV.model\",\n",
    "                                            \"description\":\"Moddeled storage\",\n",
    "                                                 \"units\": units[name]})\n",
    "        data_vars[name] = storage_terms_i\n",
    "\n",
    "    ds_combined = xr.Dataset(data_vars,\n",
    "                             attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                    \"history\": f\"Storage term results from ewatercycle_HBV.model\",}\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f44bc9-28af-41bf-82c0-f93cb7c6cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save? \n",
    "if save:\n",
    "    storage_terms_ds.to_netcdf(r'Output/storage_terms_ds.nc')\n",
    "    parameter_terms_ds.to_netcdf(r'Output/parameter_terms_ds.nc')\n",
    "    ds_combined.to_netcdf(r'Output/combined_ds.nc')\n",
    "    \n",
    "if load:\n",
    "    storage_terms_ds = xr.open_dataarray(r'Output/storage_terms_ds.nc')\n",
    "    parameter_terms_ds = xr.open_dataarray(r'Output/parameter_terms_ds.nc')\n",
    "    ds_combined = xr.open_dataset(r'Output/combined_ds.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c99d78a-9b2f-4418-b7d2-7b48e5d6a403",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941203c-e86b-42b9-8449-988d5a34c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble.plot()\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "# ax.plot(ds.time.values[:n_days],ds['Q'].values[:n_days],lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color=\"k\")\n",
    "# ax.plot(df.index, Q_m_in_ref[1:],label=\"Modelled reference Q\");\n",
    "df_Q.loc[Q_obs_t_lst,\"Q\"].plot(ax=ax,lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color='k')\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "df_ensemble.plot(ax=ax,alpha=0.5,zorder=-1,legend=False)\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "ax.set_xlim((pd.Timestamp('1997-08-01'),pd.Timestamp('1999-01-01')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23320916-e84c-459c-b4e1-b0e892f813d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path = path / \"Figures\"\n",
    "current_time = str(datetime.now())[:-10].replace(\":\",\"_\")\n",
    "fig.savefig(figure_path / f\"ensemble_run_for_{n_particles}_particles_{current_time}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c7c94-9525-45a1-b7d4-6437964196aa",
   "metadata": {},
   "source": [
    "Can calculate the mean of 50 particles as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59377984-0f40-4143-9ebd-ab058886e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ensemble = df_ensemble.T.mean()\n",
    "# NSE_mean_ens = calc_NSE(df_Q.loc[Q_obs_t_lst,\"Q\"],mean_ensemble.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64906eb1-eff6-4562-bd55-7bb5edbd4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble.plot()\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "# ax.plot(ds.time.values[:n_days],ds['Q'].values[:n_days],lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color=\"k\")\n",
    "# ax.plot(df.index, Q_m_in_ref[1:],label=\"Modelled reference Q\");\n",
    "df_Q.loc[Q_obs_t_lst,\"Q\"].plot(ax=ax,lw=0,marker=\"*\",ms=2.0,zorder=0,label=\"Observations\",color='k')\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.35,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "ax.set_xlim((pd.Timestamp('1997-08-01'),pd.Timestamp('1998-06-01')))\n",
    "figure_path = path / \"Figures\"\n",
    "fig.savefig(figure_path / f\"ensemble_run_for_{n_particles}_particles_{current_time}.png\",bbox_inches=\"tight\",dpi=400);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abd739-6157-4e5a-94f8-4a2637d1eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble.plot()\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "# ax.plot(ds.time.values[:n_days],ds['Q'].values[:n_days],lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color=\"k\")\n",
    "# ax.plot(df.index, Q_m_in_ref[1:],label=\"Modelled reference Q\");\n",
    "df_Q.loc[Q_obs_t_lst,\"Q\"].plot(ax=ax,lw=0,marker=\"*\",ms=2.0,zorder=0,label=\"Observations\",color='k')\n",
    "\n",
    "ax_pr = ax.twinx()\n",
    "ax_pr.invert_yaxis()\n",
    "ax_pr.set_ylabel(f\"P [mm]\")\n",
    "ax_pr.bar(df_ensemble.index,ds['pr'].values[:n_timesteps],zorder=-15,label=\"Precipitation\",color=\"grey\")\n",
    "ax_pr.legend(bbox_to_anchor=(1.25,0.8))\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.35,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "\n",
    "figure_path = path / \"Figures\"\n",
    "fig.savefig(figure_path / f\"ensemble_run_for_{n_particles}_particles_bounds_P_{current_time}.png\",bbox_inches=\"tight\",dpi=400);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8e3b3-3454-4ee5-96f1-964f1cdf4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "fig, axs = plt.subplots(n,1,figsize=(12,n*2),sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "df_Q.loc[Q_obs_t_lst,\"Q\"].plot(ax=ax,lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color='k')\n",
    "ax_pr = ax.twinx()\n",
    "ax_pr.invert_yaxis()\n",
    "ax_pr.set_ylabel(f\"P [mm]\")\n",
    "ax_pr.bar(df_ensemble.index,ds['pr'].values[:n_timesteps],zorder=-10,label=\"Precipitation\",color=\"grey\")\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.5,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "\n",
    "for i, S_name in enumerate(S_names):\n",
    "    for j in range(n_particles):\n",
    "        storage_terms_ds.isel(storage=i,EnsembleMember=j).plot(ax=axs[i+1],color=f\"C{i}\",alpha=0.5)\n",
    "        axs[i+1].set_title(S_name)\n",
    "\n",
    "# remove all unncecearry xlabels\n",
    "[ax.set_xlabel(None) for ax in axs[:-1]]\n",
    "[ax.set_ylabel(\"S [mm]\") for ax in axs[1:]]\n",
    "figure_path = path / \"Figures\"\n",
    "fig.savefig(figure_path / f\"ensemble_run_for__{n_particles}_particles_storages_{current_time}.png\",bbox_inches=\"tight\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b4ea15-2374-49ca-80be-bb4de67c7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "for i in range(n_particles):\n",
    "    storage_terms_ds.sel(storage=\"Ss\").isel(EnsembleMember=i).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc02d3a-5867-46bb-ae1d-7dce4e8d338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "parameter=\"Tlag\"\n",
    "for i in range(n_particles):\n",
    "    parameter_terms_ds.sel(parameter=parameter).isel(EnsembleMember=i).plot(ax=ax)\n",
    "ax.set_title(f'parameter={parameter} for {n_particles} Ensemble Members')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238fdbc0-9386-400e-b15a-209403d6232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4,figsize=(25,10),sharex=True)\n",
    "axs = axs.flatten()\n",
    "for j, parameter in enumerate(param_names):\n",
    "    ax = axs[j]\n",
    "    for i in range(n_particles):\n",
    "        parameter_terms_ds.sel(parameter=parameter).isel(EnsembleMember=i).plot(ax=ax,alpha=0.3)\n",
    "    ax.set_title(f'parameter={parameter}')# for {n_particles} Ensemble Members')\n",
    "    ax.set_ylabel(f'[{units[parameter]}]')\n",
    "figure_path = path / \"Figures\"\n",
    "fig.savefig(figure_path /  f\"ensemble_run_for__{n_particles}_particles_parameters_{current_time}.png\",bbox_inches=\"tight\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9cfda7-fd88-4722-aba3-a8cbad0cad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
