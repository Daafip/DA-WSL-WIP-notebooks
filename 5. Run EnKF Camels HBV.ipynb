{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cd8d85-eb4a-45d6-925a-e3e770592043",
   "metadata": {},
   "source": [
    "### Import modules and verify they work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7e710a-5aa4-40f9-a1cb-151e3cddbe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "import xarray as xr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4569a0f2-4bea-48cc-b5a4-ca5384e368c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general eWC\n",
    "import ewatercycle\n",
    "import ewatercycle.models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1454a07-6f82-4728-87cc-f799951db83d",
   "metadata": {},
   "source": [
    "Download plugin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a3463b-eedd-4f59-a542-6afd58cf6eb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install ewatercycle-HBV==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111bc65b-8299-43ba-95fd-e92df6b92707",
   "metadata": {},
   "source": [
    "#### set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df66893d-b667-4fcc-a841-683f32ed2cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/davidhaasnoot/eWaterCycle-WSL-WIP/Forcing')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.cwd()\n",
    "forcing_path = path / \"Forcing\"\n",
    "observations_path = path / \"Observations\"\n",
    "figure_path = path / \"Figures\"\n",
    "output_path = path / \"Output\"\n",
    "forcing_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787c692-3f9c-402b-9b48-93daeeb47926",
   "metadata": {},
   "source": [
    "#### add parameter info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33fbba0f-dbc0-4812-9125-79e0df831e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Array of initial storage terms - we keep these constant for now \n",
    "##              Si,  Su, Sf, Ss\n",
    "s_0 = np.array([0,  100,  0,  5])\n",
    "\n",
    "## Array of parameters min/max bounds as a reference\n",
    "##                      Imax,  Ce,  Sumax, beta,  Pmax,  T_lag,   Kf,   Ks\n",
    "p_min_initial= np.array([0,   0.2,  40,    .5,   .001,   1,     .01,  .0001])\n",
    "p_max_initial = np.array([8,    1,  800,   4,    .3,     10,    .1,   .01])\n",
    "p_names = [\"$I_{max}$\",  \"$C_e$\",  \"$Su_{max}$\", \"Î²\",  \"$P_{max}$\",  \"$T_{lag}$\",   \"$K_f$\",   \"$K_s$\"]\n",
    "S_names = [\"Interception storage\", \"Unsaturated Rootzone Storage\", \"Fastflow storage\", \"Groundwater storage\"]\n",
    "param_names = [\"Imax\",\"Ce\",  \"Sumax\", \"Beta\",  \"Pmax\",  \"Tlag\",   \"Kf\",   \"Ks\"]\n",
    "stor_names = [\"Si\", \"Su\", \"Sf\", \"Ss\"]\n",
    "\n",
    "# set initial as mean of max,min\n",
    "par_0 = (p_min_initial + p_max_initial)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03aea008-87ce-4d09-8d01-f12dfe6bb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_start_date = \"1997-10-01T00:00:00Z\"\n",
    "experiment_end_date = \"1999-12-01T00:00:00Z\"\n",
    "HRU_id = 1620500\n",
    "alpha = 1.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41855c32-2650-403e-bcad-332eab6c1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewatercycle_HBV.forcing import HBVForcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc7e4f93-a69a-4d20-8844-92deea52fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: get alpha correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6249ec9f-8ff2-4181-ac6f-cac309d8cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_forcing = HBVForcing(start_time = experiment_start_date,\n",
    "                          end_time = experiment_end_date,\n",
    "                          directory = forcing_path,\n",
    "                          camels_file = f'0{HRU_id}_lump_cida_forcing_leap.txt',\n",
    "                          alpha = alpha\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944e1b8-e225-483d-b39e-74ed4dea37cf",
   "metadata": {},
   "source": [
    "#### import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db8a9b3-2076-4726-9dd2-5c7808ac08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewatercycle.models import HBV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a379652-b6e6-42ba-9df2-2b67b90a6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_type = \"EnFK\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd67cd-b327-475a-9315-0f199c317718",
   "metadata": {},
   "source": [
    "# run EnFK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f50865-ce08-4be1-8abf-09ccc80cd97c",
   "metadata": {},
   "source": [
    "n = number of elements in state vector: parameters + states \\\n",
    "N = number of particles \\\n",
    "m = number of observations \\\n",
    "D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "434c5cd9-b42e-4a2f-afdf-a407758b3463",
   "metadata": {},
   "source": [
    "![Algorithm_6_Subspace_EnKF_update_Data_Assimilation_Fundamentals_DOI_978-3-030-96709-3_8.png](Figures/NB_Figures/Algorithm_6_Subspace_EnKF_update_Data_Assimilation_Fundamentals_DOI_978-3-030-96709-3_8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147e4a20-0a8c-497e-9301-c38ebe57c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rng = np.random.default_rng() # Initiate a Random Number Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f410ac41-48a8-4232-bde8-957e94783852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_EnFK(n_particles, p_max_initial, p_min_initial, alpha, s_0):\n",
    "    # for initial run sample a set of parameters - start with simpel linear random:  min+[0,1] * (max-min) -> easily changes after\n",
    "    array_random_num = np.array([[np.random.random() for i in range(len(p_max_initial))] for i in range(n_particles)])\n",
    "    p_initial = p_min_initial + array_random_num * (p_max_initial-p_min_initial)\n",
    "    s_initial = np.array([s_0  for i in range(n_particles)]) # for now constant\n",
    "    prior_state_vector_z = np.hstack((p_initial, s_initial)).T # combine to a state vector: shape 12 x n_particles\n",
    "    \n",
    "    ensemble = []\n",
    "    for i in range(n_particles):\n",
    "        ensemble.append(HBV(forcing=test_forcing))\n",
    "        \n",
    "    for index, ensembleMember in enumerate(ensemble):\n",
    "        config_file, _ = ensembleMember.setup(\n",
    "                                              parameters=','.join([str(p) for p in p_initial[index]]), \n",
    "                                              initial_storage=','.join([str(s) for s in s_initial[index]]),\n",
    "                                              alpha=alpha\n",
    "                                             )\n",
    "        ensembleMember.initialize(config_file)\n",
    "\n",
    "    \n",
    "    return ensemble, prior_state_vector_z\n",
    "\n",
    "# def generate_weights(Q_m_at_ts, obs):\n",
    "#     \"Takes the enseble and observations and returns the posterior\"\n",
    "#     prior = Q_m_at_ts # take last observation\n",
    "#     innov2 = (obs - prior)\n",
    "#     like_sigma = 0.05  # In [m]; so 5 mm\n",
    "#     unnormalised_log_weights = scipy.stats.norm.logpdf(innov2, loc=0, scale=like_sigma)\n",
    "#     normalised_weights = np.exp(unnormalised_log_weights - scipy.special.logsumexp(unnormalised_log_weights))\n",
    "#     return normalised_weights\n",
    "\n",
    "def add_noise(like_sigma):\n",
    "    return rng.normal(loc=0, scale=like_sigma)   # log normal so can't go to 0 ? \n",
    "\n",
    "def calc_NSE(Qo, Qm):\n",
    "    QoAv  = np.mean(Qo)\n",
    "    ErrUp = np.sum((Qm - Qo)**2)\n",
    "    ErrDo = np.sum((Qo - QoAv)**2)\n",
    "    return 1 - (ErrUp / ErrDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "744707a1-d095-458f-8a59-d4cad98b8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 100 # 50 seems max for current setup :P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa45e7b-7070-404c-a198-13995bdbd0d9",
   "metadata": {},
   "source": [
    "###### \n",
    "#### if fails, run in cmd:\n",
    "[link1](https://stackoverflow.com/questions/65272764/ports-are-not-available-listen-tcp-0-0-0-0-50070-bind-an-attempt-was-made-to)\n",
    "[link2](https://asheroto.medium.com/docker-error-an-attempt-was-made-to-access-a-socket-in-a-way-forbidden-by-its-access-permissions-15a444ab217b)\n",
    "```bash\n",
    "net stop winnat\n",
    "netsh int ipv4 set dynamic tcp start=49152 num=16384\n",
    "netsh int ipv6 set dynamic tcp start=49152 num=16384\n",
    "net start winnat\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6c859e-4b52-4ed3-87ac-47face95a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # #### run if fails \n",
    "# for index, ensembleMember in enumerate(ensemble):\n",
    "#     ensembleMember.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b2507f-d55a-4828-9aa6-a3da9d7ac4af",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "500 Server Error for http+docker://localhost/v1.44/containers/b6bdee55fb1aca61f4ed4f14b1cec9f16e742e75b5c58a25811edee9bfbdc0ff/start: Internal Server Error (\"Ports are not available: exposing port TCP 0.0.0.0:50399 -> 0.0.0.0:0: listen tcp 0.0.0.0:50399: bind: An attempt was made to access a socket in a way forbidden by its access permissions.\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/docker/api/client.py:265\u001b[0m, in \u001b[0;36mAPIClient._raise_for_status\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: http+docker://localhost/v1.44/containers/b6bdee55fb1aca61f4ed4f14b1cec9f16e742e75b5c58a25811edee9bfbdc0ff/start",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create list of ensemble members\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ensemble, prior_state_vector_z  \u001b[38;5;241m=\u001b[39m \u001b[43msetup_EnFK\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_particles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_max_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_min_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m ref_model \u001b[38;5;241m=\u001b[39m ensemble[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36msetup_EnFK\u001b[0;34m(n_particles, p_max_initial, p_min_initial, alpha, s_0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     ensemble\u001b[38;5;241m.\u001b[39mappend(HBV(forcing\u001b[38;5;241m=\u001b[39mtest_forcing))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, ensembleMember \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ensemble):\n\u001b[0;32m---> 13\u001b[0m     config_file, _ \u001b[38;5;241m=\u001b[39m \u001b[43mensembleMember\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp_initial\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43minitial_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms_initial\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     ensembleMember\u001b[38;5;241m.\u001b[39minitialize(config_file)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensemble, prior_state_vector_z\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/ewatercycle/base/model.py:117\u001b[0m, in \u001b[0;36meWaterCycleModel.setup\u001b[0;34m(self, cfg_dir, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfg_dir: Path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_cfg_dir(cfg_dir)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfg_file: Path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_cfg_file(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bmi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_bmi_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfg_file), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfg_dir)\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/ewatercycle/base/model.py:446\u001b[0m, in \u001b[0;36mContainerizedModel._make_bmi_instance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforcing:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_additional_input_dirs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforcing\u001b[38;5;241m.\u001b[39mdirectory))\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_container\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmi_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cfg_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_additional_input_dirs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/ewatercycle/container.py:177\u001b[0m, in \u001b[0;36mstart_container\u001b[0;34m(work_dir, image, input_dirs, image_port, timeout, delay, wrappers)\u001b[0m\n\u001b[1;32m    174\u001b[0m     input_dirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocker\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 177\u001b[0m     bmi \u001b[38;5;241m=\u001b[39m \u001b[43mstart_docker_container\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapptainer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    181\u001b[0m     bmi \u001b[38;5;241m=\u001b[39m start_apptainer_container(\n\u001b[1;32m    182\u001b[0m         work_dir,\n\u001b[1;32m    183\u001b[0m         image,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m         delay,\n\u001b[1;32m    187\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/ewatercycle/container.py:268\u001b[0m, in \u001b[0;36mstart_docker_container\u001b[0;34m(work_dir, image, input_dirs, image_port, timeout, delay)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start Docker container with model inside.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    Bmi object which wraps the container.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBmiClientDocker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocker_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_dirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dirs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# https://github.com/eWaterCycle/grpc4bmi/issues/95\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# https://github.com/eWaterCycle/grpc4bmi/issues/100\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt spawn container within allocated time limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds). You may try pulling the docker image with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `docker pull \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` and then try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/grpc4bmi/bmi_client_docker.py:85\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, image, work_dir, image_port, host, input_dirs, user, remove, delay, timeout)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotADirectoryError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwork_dir)\n\u001b[1;32m     84\u001b[0m volumes[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwork_dir] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwork_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrw\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer: Container \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcontainers\u001b[38;5;241m.\u001b[39mrun(image,\n\u001b[1;32m     86\u001b[0m                                        ports\u001b[38;5;241m=\u001b[39m{\u001b[38;5;28mstr\u001b[39m(image_port) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m: port},\n\u001b[1;32m     87\u001b[0m                                        volumes\u001b[38;5;241m=\u001b[39mvolumes,\n\u001b[1;32m     88\u001b[0m                                        working_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwork_dir,\n\u001b[1;32m     89\u001b[0m                                        user\u001b[38;5;241m=\u001b[39muser,\n\u001b[1;32m     90\u001b[0m                                        remove\u001b[38;5;241m=\u001b[39mremove,\n\u001b[1;32m     91\u001b[0m                                        detach\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     92\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(delay)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remove:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# Only able to reload, read logs on exited container when remove=False\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/docker/models/containers.py:880\u001b[0m, in \u001b[0;36mContainerCollection.run\u001b[0;34m(self, image, command, stdout, stderr, remove, **kwargs)\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mpull(image, platform\u001b[38;5;241m=\u001b[39mplatform)\n\u001b[1;32m    877\u001b[0m     container \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate(image\u001b[38;5;241m=\u001b[39mimage, command\u001b[38;5;241m=\u001b[39mcommand,\n\u001b[1;32m    878\u001b[0m                             detach\u001b[38;5;241m=\u001b[39mdetach, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 880\u001b[0m \u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detach:\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m container\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/docker/models/containers.py:417\u001b[0m, in \u001b[0;36mContainer.start\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    409\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m    Start this container. Similar to the ``docker start`` command, but\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m    doesn't support attach options.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03m            If the server returns an error.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/docker/utils/decorators.py:19\u001b[0m, in \u001b[0;36mcheck_resource.<locals>.decorator.<locals>.wrapped\u001b[0;34m(self, resource_id, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_id:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNullResource(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResource ID was not provided\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m     )\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/docker/api/container.py:1135\u001b[0m, in \u001b[0;36mContainerApiMixin.start\u001b[0;34m(self, container, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/containers/\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m/start\u001b[39m\u001b[38;5;124m\"\u001b[39m, container)\n\u001b[1;32m   1134\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(url)\n\u001b[0;32m-> 1135\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/docker/api/client.py:267\u001b[0m, in \u001b[0;36mAPIClient._raise_for_status\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    265\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mcreate_api_error_from_http_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ewatercycle/lib/python3.10/site-packages/docker/errors.py:39\u001b[0m, in \u001b[0;36mcreate_api_error_from_http_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m NotFound\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(e, response\u001b[38;5;241m=\u001b[39mresponse, explanation\u001b[38;5;241m=\u001b[39mexplanation) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mAPIError\u001b[0m: 500 Server Error for http+docker://localhost/v1.44/containers/b6bdee55fb1aca61f4ed4f14b1cec9f16e742e75b5c58a25811edee9bfbdc0ff/start: Internal Server Error (\"Ports are not available: exposing port TCP 0.0.0.0:50399 -> 0.0.0.0:0: listen tcp 0.0.0.0:50399: bind: An attempt was made to access a socket in a way forbidden by its access permissions.\")"
     ]
    }
   ],
   "source": [
    "# create list of ensemble members\n",
    "ensemble, prior_state_vector_z  = setup_EnFK(n_particles, p_max_initial, p_min_initial, alpha, s_0)\n",
    "ref_model = ensemble[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf2cd8f-3cc3-491d-9ec6-a8b440067425",
   "metadata": {},
   "source": [
    "### import observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c49bc88-ae41-40bd-bdee-375b241a73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(forcing_path / ref_model.forcing.pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788bf40-4cc4-45b4-b999-ffbe4f25cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = observations_path / f'0{HRU_id}_streamflow_qc.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f884c9d-a19b-4d21-8686-1abb1017fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubic_ft_to_cubic_m = 0.0283168466 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb63f5-c1a9-4485-b96a-aa3762f1bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_header = ['GAGEID','Year','Month', 'Day', 'Streamflow(cubic feet per second)','QC_flag']\n",
    "new_header_dict = dict(list(zip(range(len(new_header)),new_header)))\n",
    "\n",
    "df_Q = pd.read_fwf(observations,delimiter=' ',encoding='utf-8',header=None)\n",
    "df_Q = df_Q.rename(columns=new_header_dict)\n",
    "df_Q['Streamflow(cubic feet per second)'] = df_Q['Streamflow(cubic feet per second)'].apply(lambda x: np.nan if x==-999.00 else x)\n",
    "df_Q['Q (m3/s)'] = df_Q['Streamflow(cubic feet per second)'] * cubic_ft_to_cubic_m\n",
    "df_Q['Q'] = df_Q['Q (m3/s)'] / ds.attrs['area basin(m^2)'] * 3600 * 24 * 1000 # m3/s -> m/s ->m/d -> mm/d\n",
    "df_Q.index = df_Q.apply(lambda x: pd.Timestamp(f'{int(x.Year)}-{int(x.Month)}-{int(x.Day)}'),axis=1)\n",
    "df_Q.index.name = \"time\"\n",
    "df_Q.drop(columns=['Year','Month', 'Day','Streamflow(cubic feet per second)'],inplace=True)\n",
    "df_Q = df_Q.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470add53-a8b1-45f2-a84f-2b06b6ea37db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_Q['Q'].plot()\n",
    "# ax.set_xlim((pd.Timestamp('1997-08-01'),pd.Timestamp('1998-06-01')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e458a3-a255-48ae-93e5-d8102ff481c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = len(ds.time.values) - 1\n",
    "# n_timesteps  = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6032900-28da-400c-a1bd-fdd213c737d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92804088-8dad-442b-b60b-bd68eeb41d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrsa for EnKF\n",
    "measurement_vector_D = np.matrix(np.zeros((n_timesteps, n_particles))) # m x N = n_timsteps x n_particles\n",
    "PI = np.matrix((np.identity(n_particles) - (( np.ones(n_particles) @ np.ones(n_particles).T ) / n_particles) ) / (np.sqrt(n_particles - 1)))\n",
    "A_cross_A = np.matrix((np.identity(n_particles) - (( np.ones(n_particles) @ np.ones(n_particles).T ) / n_particles) ))\n",
    "\n",
    "# set up arrays _ same as PF\n",
    "n_storage_terms = len(stor_names)\n",
    "n_param_terms = len(param_names)\n",
    "Q_m_arr = np.zeros((n_particles, n_timesteps))\n",
    "storage_terms_arr = np.zeros((n_particles, n_timesteps, n_storage_terms))\n",
    "parameter_terms_arr = np.zeros((n_particles, n_timesteps, n_param_terms))\n",
    "t_lag_max = 100 # for now? \n",
    "index_t_lag = 5 # fith parameter (base 0)\n",
    "print(f'{index_t_lag}th index is {param_names[index_t_lag]}')\n",
    "lag_vector_memory_arr = np.zeros((n_particles, n_timesteps,t_lag_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313b1f6-b54d-4d58-93fc-dec65520bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param_names)\n",
    "print(stor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673817c7-a424-4c5d-baad-1d856664488f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "time = []\n",
    "Q_obs_t_lst = []\n",
    "t_index = 0 \n",
    "sigma_obs = 1e-5\n",
    "## running for whole timeseries takes long, just do first couple of months to see inpact\n",
    "# while ref_model.time < ref_model.start_time + 6* ref_model.time_step:\n",
    "while ref_model.time < ref_model.end_time:\n",
    "\n",
    "    time.append(pd.Timestamp(ref_model.time_as_datetime.date()))\n",
    "    print(f'{t_index}/{n_timesteps}',end=\"\\r\")\n",
    "    # run model forward\n",
    "    for m_index, ensembleMember in tqdm(enumerate(ensemble),disable=True):\n",
    "        ensembleMember.update()\n",
    "        # get model, storage and paramers\n",
    "        Q_m_arr[m_index, t_index] = ensembleMember.get_value(\"Q_m\")[0] # 1 observation per ensemble member - TODO: would be great to just do this in one go!\n",
    "        storage_terms_arr[m_index, t_index] = np.array([ensembleMember.get_value(storage) for storage in stor_names]).flatten().copy()\n",
    "        parameter_terms_arr[m_index, t_index] = np.array([ensembleMember.get_value(parameter) for parameter in param_names]).flatten().copy()\n",
    "\n",
    "\n",
    "        # get the memory vector\n",
    "        t_lag = int(parameter_terms_arr[m_index, t_index, index_t_lag])\n",
    "        lag_vector_memory_arr[m_index, t_index, :t_lag] = np.array([ensembleMember.get_value(f\"memory_vector{i}\") for i in range(t_lag)]).flatten()\n",
    "    \n",
    "\n",
    "    prior_state_vector_Z = np.hstack((parameter_terms_arr[:,t_index], storage_terms_arr[:,t_index])).T\n",
    "    # if t_index % 1 == 0:\n",
    "    ### resample\n",
    "    Q_obs_t_lst.append(pd.Timestamp(ref_model.time_as_datetime.date()))\n",
    "\n",
    "    # obtain pertubed measurements\n",
    "    measurement_d  = df_Q.loc[pd.Timestamp(ref_model.time_as_datetime.date()),\"Q\"]\n",
    "    measurement_pertubation_matrix_E = np.array([add_noise(sigma_obs) for x in range(n_particles)])\n",
    "    peturbed_measurements_D = measurement_d * np.ones(n_particles).T + np.sqrt(n_particles - 1) * measurement_pertubation_matrix_E\n",
    "    measurement_vector_D[t_index, :] = peturbed_measurements_D\n",
    "\n",
    "    # retrieve predicted values from model \n",
    "    predicted_measurements_Ypsilon = Q_m_arr[:, t_index]\n",
    "\n",
    "    # algorithm:\n",
    "\n",
    "    # reporject\n",
    "    E = np.matrix(peturbed_measurements_D) * PI\n",
    "    Y = np.matrix(predicted_measurements_Ypsilon) * PI\n",
    "    if prior_state_vector_Z.shape[0] < n_particles - 1:\n",
    "        Y = Y * A_cross_A\n",
    "    S = Y\n",
    "    D_tilde = np.matrix(peturbed_measurements_D - predicted_measurements_Ypsilon)\n",
    "    \n",
    "    W = S.T * np.linalg.inv(S * S.T + E * E.T) * D_tilde\n",
    "    T = np.identity(n_particles) + (W / np.sqrt(n_particles-1))\n",
    "\n",
    "    post_state_vector_Z = prior_state_vector_Z * T\n",
    "    \n",
    "    # resample\n",
    "    new_parameters = post_state_vector_Z.T[:,:n_param_terms]\n",
    "    new_storage    = post_state_vector_Z.T[:,n_param_terms:]\n",
    "    new_lag        = lag_vector_memory_arr[:,t_index].copy() # dont have a way to set new lag function as of yet    \n",
    "    \n",
    "    \n",
    "    # update the parameters & states\n",
    "    for index, ensembleMember in tqdm(enumerate(ensemble),disable=True):\n",
    "        # TODO: adjust so that tLag cant go to 0\n",
    "        new_parameters[index, index_t_lag] = 1 # set t_lag to 1\n",
    "        [ensembleMember.set_value(parameter, np.array([new_parameters[index, p_index]])) for p_index, parameter in enumerate(param_names)]\n",
    "        [ensembleMember.set_value(storage, np.array([new_storage[index, s_index]])) for s_index, storage in enumerate(stor_names)]\n",
    "        new_tlag = new_parameters[index, index_t_lag]\n",
    "        # new_tlag = 1 #? for now??\n",
    "        [ensembleMember.set_value(f\"memory_vector{mem_index}\", np.array([new_lag[index, mem_index]])) for mem_index in range(int(new_tlag))]\n",
    "\n",
    "    # advance the index\n",
    "    t_index+=1 \n",
    "\n",
    "print('Finalising')\n",
    "# end model - IMPORTANT! when working with dockers\n",
    "for index, ensembleMember in tqdm(enumerate(ensemble),disable=True):\n",
    "    ensembleMember.finalize()\n",
    "\n",
    "\n",
    "end = datetime.now()\n",
    "run = end - start\n",
    "print(f'{run.seconds//60}min,{run.seconds%60}sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9f321-0273-493b-8930-a260fad4da2b",
   "metadata": {},
   "source": [
    "### process the numpy data into easily acessed data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad75ed7-4d48-44d2-93af-d3b7acfa530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save, load = False, False\n",
    "current_time = str(datetime.now())[:-10].replace(\":\",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e4052-17f9-4b09-84dc-433b890d6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load:\n",
    "    df_ensemble = pd.DataFrame(data=Q_m_arr[:,:len(time)].T,index=time,columns=[f'particle {n}' for n in range(n_particles)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ecfa5-1266-4e6d-bcde-cb51f0d5cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_ensemble);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d633e81-978b-4b1b-827b-b1940fc9c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_n = df_ensemble.iloc[50:80]\n",
    "ax=df_first_n.plot(legend=False, zorder=-1)\n",
    "df_Q.loc[df_first_n.index,'Q'].plot(ax=ax,marker=\"*\",color=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5174a-c0f0-4ab7-bcb0-8a10414d50ed",
   "metadata": {},
   "source": [
    "### process states and parameters into xarrys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95343676-2174-47aa-8e08-612b4ec4cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save? \n",
    "if save:\n",
    "    df_ensemble.to_feather(output_path /f'df_ensemble_{da_type}_{current_time}.feather')\n",
    "if load:\n",
    "    df_ensemble = pd.read_feather(glob.glob(str(output_path/'df_ensemble_*.feather'))[-1]) # read last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cbd7a-3941-403e-9347-aaa972794f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if load:\n",
    "# TODO: obtain from model \n",
    "units= {\"Imax\":\"mm\",\n",
    "        \"Ce\": \"-\",\n",
    "        \"Sumax\": \"mm\",\n",
    "        \"Beta\": \"-\",\n",
    "        \"Pmax\": \"mm\",\n",
    "        \"Tlag\": \"d\",\n",
    "        \"Kf\": \"-\",\n",
    "        \"Ks\": \"-\",\n",
    "        \"Si\": \"mm\",\n",
    "        \"Su\": \"mm\",\n",
    "        \"Sf\": \"mm\",\n",
    "        \"Ss\": \"mm\",\n",
    "        \"Ei_dt\": \"mm/d\",\n",
    "        \"Ea_dt\": \"mm/d\",\n",
    "        \"Qs_dt\": \"mm/d\",\n",
    "        \"Qf_dt\": \"mm/d\",\n",
    "        \"Q_tot_dt\": \"mm/d\",\n",
    "        \"Q_m\": \"mm/d\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce2567-5092-4e57-b625-f2c5905e4f92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not load:\n",
    "    # combine the 3D numpy arr into one dataArray\n",
    "    storage_terms_ds = xr.DataArray(storage_terms_arr,dims=[\"EnsembleMember\",\"time\",\"storage\"],\n",
    "                                    coords=[np.arange(n_particles),df_ensemble.index,stor_names],\n",
    "                                    attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                           \"history\": f\"Storage term results from ewatercycle_HBV.model\",\n",
    "                                        \"description\":\"Moddeled storage\",\n",
    "                                             \"units\": \"mm\"})\n",
    "    \n",
    "    parameter_terms_ds = xr.DataArray(parameter_terms_arr,dims=[\"EnsembleMember\",\"time\",\"parameter\"],\n",
    "                                coords=[np.arange(n_particles),df_ensemble.index,param_names],\n",
    "                                    attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                           \"history\": f\"Storage terms results from ewatercycle_HBV.model\",})\n",
    "    \n",
    "    # even better is to combine into one Data_set_- this is most intuitive way for me - probably more ways\n",
    "    data_vars = {}\n",
    "    for i, name in enumerate(stor_names):\n",
    "        storage_terms_i = xr.DataArray(storage_terms_arr[:,:,i],\n",
    "                                       name=name,\n",
    "                                       dims=[\"EnsembleMember\",\"time\"],\n",
    "                                      coords=[np.arange(n_particles),df_ensemble.index],\n",
    "                                      attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                               \"history\": f\"Storage term results from ewatercycle_HBV.model\",\n",
    "                                            \"description\":\"Moddeled storage\",\n",
    "                                                 \"units\": \"mm\"})\n",
    "        data_vars[name] = storage_terms_i\n",
    "    for i, name in enumerate(param_names):\n",
    "        storage_terms_i = xr.DataArray(parameter_terms_arr[:,:,i],\n",
    "                                       name=name,\n",
    "                                       dims=[\"EnsembleMember\",\"time\"],\n",
    "                                      coords=[np.arange(n_particles),df_ensemble.index],\n",
    "                                      attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                               \"history\": f\"Storage term results from ewatercycle_HBV.model\",\n",
    "                                            \"description\":\"Moddeled storage\",\n",
    "                                                 \"units\": units[name]})\n",
    "        data_vars[name] = storage_terms_i\n",
    "\n",
    "    ds_combined = xr.Dataset(data_vars,\n",
    "                             attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                    \"history\": f\"Storage term results from ewatercycle_HBV.model\",}\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f44bc9-28af-41bf-82c0-f93cb7c6cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save? \n",
    "if save:\n",
    "    storage_terms_ds.to_netcdf(output_path / f'storage_terms_ds_{da_type}_{current_time}.nc')\n",
    "    parameter_terms_ds.to_netcdf(output_path / f'parameter_terms_ds_{da_type}_{current_time}.nc')\n",
    "    ds_combined.to_netcdf(output_path / f'combined_ds_{da_type}_{current_time}.nc')\n",
    "    \n",
    "if load:\n",
    "    storage_terms_ds = xr.open_dataarray(glob.glob(str(output_path / r'storage_terms_ds_*.nc'))[-1])\n",
    "    parameter_terms_ds = xr.open_dataarray(glob.glob(str(output_path / 'parameter_terms_ds_*.nc'))[-1])\n",
    "    ds_combined = xr.open_dataset(glob.glob(str(output_path / 'combined_ds_*.nc'))[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c99d78a-9b2f-4418-b7d2-7b48e5d6a403",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941203c-e86b-42b9-8449-988d5a34c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble.plot()\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "# ax.plot(ds.time.values[:n_days],ds['Q'].values[:n_days],lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color=\"k\")\n",
    "# ax.plot(df.index, Q_m_in_ref[1:],label=\"Modelled reference Q\");\n",
    "df_Q.loc[Q_obs_t_lst,\"Q\"].plot(ax=ax,lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color='k')\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "df_ensemble.plot(ax=ax,alpha=0.5,zorder=-1,legend=False)\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "ax.set_xlim((pd.Timestamp('1997-08-01'),pd.Timestamp('1998-12-01')))\n",
    "# ax.set_ylim((0,10))\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for_{n_particles}_members_{da_type}_{current_time}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c7c94-9525-45a1-b7d4-6437964196aa",
   "metadata": {},
   "source": [
    "Can calculate the mean of 50 particles as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59377984-0f40-4143-9ebd-ab058886e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ensemble = df_ensemble.T.mean()\n",
    "Q_obs_t_lst_1 = Q_obs_t_lst[:-1]\n",
    "NSE_mean_ens = calc_NSE(df_Q.loc[Q_obs_t_lst_1,\"Q\"],mean_ensemble.loc[Q_obs_t_lst_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64906eb1-eff6-4562-bd55-7bb5edbd4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble.plot()\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "# ax.plot(ds.time.values[:n_days],ds['Q'].values[:n_days],lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color=\"k\")\n",
    "# ax.plot(df.index, Q_m_in_ref[1:],label=\"Modelled reference Q\");\n",
    "df_Q.loc[Q_obs_t_lst,\"Q\"].plot(ax=ax,lw=0,marker=\"*\",ms=2.0,zorder=0,label=\"Observations\",color='k')\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean={NSE_mean_ens:.2f}\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.35,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "ax.set_title(f\"Run ensemble of {n_particles} memebers {da_type} - No lag\");\n",
    "# ax.set_xlim((pd.Timestamp('1997-08-01'),pd.Timestamp('1998-06-01')))\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for_{n_particles}_members_{da_type}_{current_time}.png\",bbox_inches=\"tight\",dpi=400);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abd739-6157-4e5a-94f8-4a2637d1eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble.plot()\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "# ax.plot(ds.time.values[:n_days],ds['Q'].values[:n_days],lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color=\"k\")\n",
    "# ax.plot(df.index, Q_m_in_ref[1:],label=\"Modelled reference Q\");\n",
    "df_Q.loc[Q_obs_t_lst,\"Q\"].plot(ax=ax,lw=0,marker=\"*\",ms=2.0,zorder=0,label=\"Observations\",color='k')\n",
    "\n",
    "ax_pr = ax.twinx()\n",
    "ax_pr.invert_yaxis()\n",
    "ax_pr.set_ylabel(f\"P [mm]\")\n",
    "ax_pr.bar(df_ensemble.index,ds['pr'].values[:n_timesteps],zorder=-15,label=\"Precipitation\",color=\"grey\")\n",
    "ax_pr.legend(bbox_to_anchor=(1.25,0.8))\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.35,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for_{n_particles}_members_{da_type}_bounds_P_{current_time}.png\",bbox_inches=\"tight\",dpi=400);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8e3b3-3454-4ee5-96f1-964f1cdf4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "fig, axs = plt.subplots(n,1,figsize=(12,n*2),sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "df_Q.loc[Q_obs_t_lst,\"Q\"].plot(ax=ax,lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color='k')\n",
    "ax_pr = ax.twinx()\n",
    "ax_pr.invert_yaxis()\n",
    "ax_pr.set_ylabel(f\"P [mm]\")\n",
    "ax_pr.bar(df_ensemble.index,ds['pr'].values[:n_timesteps],zorder=-10,label=\"Precipitation\",color=\"grey\")\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.5,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "\n",
    "for i, S_name in enumerate(S_names):\n",
    "    for j in range(n_particles):\n",
    "        storage_terms_ds.isel(storage=i,EnsembleMember=j).plot(ax=axs[i+1],color=f\"C{i}\",alpha=0.5)\n",
    "        axs[i+1].set_title(S_name)\n",
    "\n",
    "# remove all unncecearry xlabels\n",
    "[ax.set_xlabel(None) for ax in axs[:-1]]\n",
    "[ax.set_ylabel(\"S [mm]\") for ax in axs[1:]]\n",
    "\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for__{n_particles}_members_{da_type}_storages_{current_time}.png\",bbox_inches=\"tight\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b4ea15-2374-49ca-80be-bb4de67c7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "for i in range(n_particles):\n",
    "    storage_terms_ds.sel(storage=\"Ss\").isel(EnsembleMember=i).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc02d3a-5867-46bb-ae1d-7dce4e8d338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "parameter=\"Tlag\"\n",
    "for i in range(n_particles):\n",
    "    parameter_terms_ds.sel(parameter=parameter).isel(EnsembleMember=i).plot(ax=ax)\n",
    "ax.set_title(f'parameter={parameter} for {n_particles} Ensemble Members')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238fdbc0-9386-400e-b15a-209403d6232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4,figsize=(25,10),sharex=True)\n",
    "axs = axs.flatten()\n",
    "for j, parameter in enumerate(param_names):\n",
    "    ax = axs[j]\n",
    "    for i in range(n_particles):\n",
    "        parameter_terms_ds.sel(parameter=parameter).isel(EnsembleMember=i).plot(ax=ax,alpha=0.3)\n",
    "    ax.set_title(f'parameter={parameter}')# for {n_particles} Ensemble Members')\n",
    "    ax.set_ylabel(f'[{units[parameter]}]')\n",
    "if save:\n",
    "    fig.savefig(figure_path /  f\"ensemble_run_for__{n_particles}_members_{da_type}_parameters_{current_time}.png\",bbox_inches=\"tight\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554309d3-a684-40ae-add6-dafe8bb3fdad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
