{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cd8d85-eb4a-45d6-925a-e3e770592043",
   "metadata": {},
   "source": [
    "### Import modules and verify they work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7e710a-5aa4-40f9-a1cb-151e3cddbe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from devtools import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4569a0f2-4bea-48cc-b5a4-ca5384e368c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general eWC\n",
    "import ewatercycle\n",
    "import ewatercycle.forcing\n",
    "import ewatercycle.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac240ea-cd32-4ab7-9c76-17bd79e4a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dae7459-8585-40f7-b4e7-392d5ac80843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ewatercycle.forcing import HBVforcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1454a07-6f82-4728-87cc-f799951db83d",
   "metadata": {},
   "source": [
    "Download plugin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9700e11c-c767-47ed-870a-d08afbf52651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall ewatercycle-HBV -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd415d7a-38b9-4124-ba09-05d21ca859ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade git+https://github.com/Daafip/ewatercycle-hbv.git@dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111bc65b-8299-43ba-95fd-e92df6b92707",
   "metadata": {},
   "source": [
    "#### set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df66893d-b667-4fcc-a841-683f32ed2cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/davidhaasnoot/eWaterCycle-WSL-WIP/nbs_29_test_direct_real_6452000/Forcing')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.cwd()\n",
    "forcing_path = path / \"Forcing\"\n",
    "observations_path = path / \"Observations\"\n",
    "figure_path = path / \"Figures\"\n",
    "output_path = path / \"Output\"\n",
    "forcing_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787c692-3f9c-402b-9b48-93daeeb47926",
   "metadata": {},
   "source": [
    "#### add parameter info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33fbba0f-dbc0-4812-9125-79e0df831e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Array of initial storage terms - we keep these constant for now \n",
    "##              Si,  Su, Sf, Ss\n",
    "s_0 = np.array([0,  100,  0,  5, 0])\n",
    "\n",
    "## Array of parameters min/max bounds as a reference\n",
    "##                      Imax,  Ce,  Sumax, beta,  Pmax,  T_lag,   Kf,   Ks, FM\n",
    "p_min_initial= np.array([0,   0.2,  40,    .5,   .001,   1,     .01,  .0001, 6])\n",
    "p_max_initial = np.array([8,    1,  800,   4,    .3,     10,    .1,   .01, 0.1])\n",
    "p_names = [\"$I_{max}$\",  \"$C_e$\",  \"$Su_{max}$\", \"Î²\",  \"$P_{max}$\",  \"$T_{lag}$\",   \"$K_f$\",   \"$K_s$\", \"FM\"]\n",
    "S_names = [\"Interception storage\", \"Unsaturated Rootzone Storage\", \"Fastflow storage\", \"Groundwater storage\", \"Snowpack storage\"]\n",
    "param_names = [\"Imax\",\"Ce\",  \"Sumax\", \"Beta\",  \"Pmax\",  \"Tlag\",   \"Kf\",   \"Ks\", \"FM\"]\n",
    "stor_names = [\"Si\", \"Su\", \"Sf\", \"Ss\", \"Sp\"]\n",
    "\n",
    "# set initial as mean of max,min\n",
    "par_0 = (p_min_initial + p_max_initial)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03aea008-87ce-4d09-8d01-f12dfe6bb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_start_date = \"1997-08-01T00:00:00Z\"\n",
    "experiment_end_date = \"1999-09-01T00:00:00Z\"\n",
    "HRU_id = 6452000\n",
    "alpha = 1.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41855c32-2650-403e-bcad-332eab6c1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewatercycle.forcing import sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f27dbd4-421d-4110-bac3-ecb832a97d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "camels_forcing = sources.HBVForcing(start_time = experiment_start_date,\n",
    "                          end_time = experiment_end_date,\n",
    "                          directory = forcing_path,\n",
    "                          camels_file = f'0{HRU_id}_lump_cida_forcing_leap.txt',\n",
    "                          alpha = alpha,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944e1b8-e225-483d-b39e-74ed4dea37cf",
   "metadata": {},
   "source": [
    "#### import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "555a3c69-953c-403b-a259-125aa8370dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewatercycle.models import HBV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce1e11-7b68-4b30-a949-f0d8b5e3719c",
   "metadata": {},
   "source": [
    "#### import DA function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234d015-98dd-486c-9888-c01dbac975ce",
   "metadata": {},
   "source": [
    "##### Or from pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784fec9a-dba3-4f9f-9104-fc2a211904af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ewatercycle_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a70b56-f8d3-4cb6-8c0f-435e561dc656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewatercycle_DA import DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "107e551f-371f-4938-959a-a697e54b11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "507275ac-4746-419f-b796-a110bc06de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = DA.Ensemble(N=n_particles)\n",
    "ensemble.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da1ea51c-84c3-431d-aa1c-41b7a994718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_random_num = np.array([[np.random.random() for i in range(len(p_max_initial))] for i in range(n_particles)])\n",
    "p_intial = p_min_initial + array_random_num * (p_max_initial-p_min_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af32a60e-4c0d-4c86-a473-76a3358bc374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values wihch you \n",
    "setup_kwargs_lst = []\n",
    "for index in range(n_particles):\n",
    "    setup_kwargs_lst.append({'parameters':','.join([str(p) for p in p_intial[index]]), \n",
    "                            'initial_storage':','.join([str(s) for s in s_0]),\n",
    "                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c089b18-45ae-4bd2-ab33-84088a77fdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e5c51a0-3c12-42e6-8bea-83bcc897e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewatercycle_DA.local_models.HBV import HBVLocal\n",
    "ensemble.loaded_models.update({'HBVLocal': HBVLocal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b485b-43fa-4645-b7d4-34031404a39d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this initializes the models for all ensemble members. \n",
    "ensemble.initialize(model_name=[\"HBVLocal\"]*n_particles,\n",
    "                    forcing=[camels_forcing]*n_particles,\n",
    "                    setup_kwargs=setup_kwargs_lst) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3a9ac-13b0-48fc-beba-84e3ba046c90",
   "metadata": {},
   "source": [
    "if fails to initialize, run in cmd:\n",
    "[link1](https://stackoverflow.com/questions/65272764/ports-are-not-available-listen-tcp-0-0-0-0-50070-bind-an-attempt-was-made-to)\n",
    "[link2](https://asheroto.medium.com/docker-error-an-attempt-was-made-to-access-a-socket-in-a-way-forbidden-by-its-access-permissions-15a444ab217b)\n",
    "```bash\n",
    "net stop winnat\n",
    "netsh int ipv4 set dynamic tcp start=49152 num=16384\n",
    "netsh int ipv6 set dynamic tcp start=49152 num=16384\n",
    "net start winnat\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93322426-59b4-47aa-8d0d-539fe1290a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #### run if initialize fails \n",
    "# ensemble.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d252ff01-2475-44d2-adad-345297a81b11",
   "metadata": {},
   "source": [
    "## Import observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf408e6-6c68-4e25-853b-598ef963c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reference model\n",
    "ref_model = ensemble.ensemble_list[0].model\n",
    "ds = xr.open_dataset(forcing_path / ref_model.forcing.pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba804a-256d-47f2-9844-650cc82a76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = observations_path / f'0{HRU_id}_streamflow_qc.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44235d5a-a940-4a0b-bf7e-396d661f4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubic_ft_to_cubic_m = 0.0283168466 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9209c-8871-4a44-9234-7bfdabbcf6f0",
   "metadata": {},
   "source": [
    "Load camels observation file and write to a netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b136561d-095c-48d2-8a76-02d1954aac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_header = ['GAGEID','Year','Month', 'Day', 'Streamflow(cubic feet per second)','QC_flag']\n",
    "new_header_dict = dict(list(zip(range(len(new_header)),new_header)))\n",
    "\n",
    "df_Q = pd.read_fwf(observations,delimiter=' ',encoding='utf-8',header=None)\n",
    "df_Q = df_Q.rename(columns=new_header_dict)\n",
    "df_Q['Streamflow(cubic feet per second)'] = df_Q['Streamflow(cubic feet per second)'].apply(lambda x: np.nan if x==-999.00 else x)\n",
    "df_Q['Q (m3/s)'] = df_Q['Streamflow(cubic feet per second)'] * cubic_ft_to_cubic_m\n",
    "df_Q['Q'] = df_Q['Q (m3/s)'] / ds.attrs['area basin(m^2)'] * 3600 * 24 * 1000 # m3/s -> m/s ->m/d -> mm/d\n",
    "df_Q.index = df_Q.apply(lambda x: pd.Timestamp(f'{int(x.Year)}-{int(x.Month)}-{int(x.Day)}'),axis=1)\n",
    "df_Q.index.name = \"time\"\n",
    "df_Q.drop(columns=['Year','Month', 'Day','Streamflow(cubic feet per second)'],inplace=True)\n",
    "df_Q = df_Q.dropna(axis=0)\n",
    "\n",
    "ds_obs_dir = observations_path / f'0{HRU_id}_streamflow_qc.nc'\n",
    "ds_obs = xr.Dataset(data_vars=df_Q[['Q']])\n",
    "if not ds_obs_dir.exists():\n",
    "    ds_obs.to_netcdf(ds_obs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327d70b2-8807-41c4-b418-fa917d68f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_Q['Q'].plot()\n",
    "ax.set_xlim((pd.Timestamp(experiment_start_date),pd.Timestamp(experiment_end_date)))\n",
    "ax.set_ylabel(\"Q (mm/d)\")\n",
    "ax.set_title(\"observations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e941c-d9ce-4cb5-99db-2c696a2d7a49",
   "metadata": {},
   "source": [
    "Load camels observation file and write to a netcdf file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d3579-aa0b-4467-81a3-6bc56b22624a",
   "metadata": {},
   "source": [
    "## setup DA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f4bb5-2822-4d5d-b9e2-39aa5212b929",
   "metadata": {},
   "source": [
    "This sets up all the require data assimilation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba8767-9a75-46df-b5de-13bf2a750224",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_like_sigma = [0.0025] * 14 + [0]\n",
    "hyper_parameters = {'like_sigma_weights' : 0.75,\n",
    "                    'like_sigma_state_vector' : lst_like_sigma,\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4fd64-5e23-4e85-be70-c2a315495a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hyper_parameters['like_sigma_state_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe0055-5e7b-483f-b11a-053988c23d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(Z):\n",
    "    if len(Z) == 15:\n",
    "        return Z[-1] \n",
    "    else: \n",
    "        raise SyntaxWarning(f\"Length of statevector should be 13 but is {len(Z)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77d003-2305-495c-b9b9-82b2fd5984f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.initialize_da_method(ensemble_method_name = \"PF\", \n",
    "                              hyper_parameters=hyper_parameters,                           \n",
    "                              state_vector_variables = \"all\", # the next three are keyword arguments but are needed. \n",
    "                              observation_path = ds_obs_dir,\n",
    "                              observed_variable_name = \"Q\",\n",
    "                              measurement_operator = H, \n",
    "                           \n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae9ea9-c292-459b-80ab-23ca1bfaa01d",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f7de0-31ae-470e-a6df-03ebb2e71dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = int((ref_model.end_time - ref_model.start_time) /  ref_model.time_step)\n",
    "\n",
    "time = []\n",
    "assimilated_times = []\n",
    "lst_state_vector = []\n",
    "lst_Q_prior = []\n",
    "lst_Q_obs = []\n",
    "lst_Q = [] \n",
    "for i in tqdm(range(n_timesteps)):    \n",
    "    time.append(pd.Timestamp(ref_model.time_as_datetime.date()))\n",
    "    lst_Q_prior.append(ensemble.get_value(\"Q\").flatten())\n",
    "    # update every 3 steps \n",
    "    if i % 3 == 0: \n",
    "        assimilate = True \n",
    "        assimilated_times.append(pd.Timestamp(ref_model.time_as_datetime.date()))\n",
    "    else:\n",
    "        assimilate = False\n",
    "    ensemble.update(assimilate=assimilate)\n",
    "     \n",
    "    lst_state_vector.append(ensemble.get_state_vector())\n",
    "    lst_Q.append(ensemble.get_value(\"Q\").flatten())\n",
    "    lst_Q_obs.append(ensemble.ensemble_method.obs)\n",
    "    # TODO: adjust so that tLag ? currently still often 3\n",
    "\n",
    "# end model - IMPORTANT! when working with dockers\n",
    "ensemble.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da18e34-2a42-4ece-af9a-76a52c29efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d86710-9ba7-434e-8f4a-03ad19d11beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = time[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf4cfd-f3b4-483b-844b-613c935b95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_m_arr = np.array(lst_Q).T\n",
    "Q_m_arr_prior = np.array(lst_Q_prior).T\n",
    "state_vector_arr = np.array(lst_state_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e2221-b067-456e-a2fe-2e6dd4a0eb1b",
   "metadata": {},
   "source": [
    "### process the numpy data into easily acessed data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d45007-7522-4bb8-892e-effe3fc3aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "save, load = False, False \n",
    "current_time = str(datetime.now())[:-10].replace(\":\",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18be3ce-5443-412a-b2b2-0d2a503ff7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8281de-8be3-4cbb-bbe1-54f083df46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load:\n",
    "    df_ensemble = pd.DataFrame(data=Q_m_arr[:,:len(time)].T,index=time,columns=[f'particle {n}' for n in range(n_particles)])\n",
    "    df_ensemble_prior = pd.DataFrame(data=Q_m_arr_prior[:,:len(time)].T,index=time,columns=[f'particle {n}' for n in range(n_particles)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e38da-8f47-4ac6-b817-679c66e559d1",
   "metadata": {},
   "source": [
    "### process states and parameters into xarrys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fedc63-fea7-444a-978e-a4e14f5e9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save? \n",
    "if save:\n",
    "    df_ensemble.to_feather(output_path /f'df_ensemble_{current_time}.feather')\n",
    "if load:\n",
    "    df_ensemble = pd.read_feather(sorted(glob.glob(str(output_path/'df_ensemble_*.feather')))[-1]) # read last\n",
    "    time = list(df_ensemble.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2b23e-ce3b-492d-bd5b-8c999eb06c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble = df_ensemble.iloc[:1000]\n",
    "# time = time[:1000]\n",
    "# state_vector_arr = state_vector_arr[:1000,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b368d94-5369-4c20-861a-249f72020b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "units= {\"Imax\":\"mm\",\n",
    "        \"Ce\": \"-\",\n",
    "        \"Sumax\": \"mm\",\n",
    "        \"Beta\": \"-\",\n",
    "        \"Pmax\": \"mm\",\n",
    "        \"Tlag\": \"d\",\n",
    "        \"Kf\": \"-\",\n",
    "        \"Ks\": \"-\",\n",
    "        \"FM\":'mm/d/degC',\n",
    "        \"Si\": \"mm\",\n",
    "        \"Su\": \"mm\",\n",
    "        \"Sf\": \"mm\",\n",
    "        \"Ss\": \"mm\",\n",
    "        \"Sp\": \"mm\",\n",
    "        \"Ei_dt\": \"mm/d\",\n",
    "        \"Ea_dt\": \"mm/d\",\n",
    "        \"Qs_dt\": \"mm/d\",\n",
    "        \"Qf_dt\": \"mm/d\",\n",
    "        \"Q_tot_dt\": \"mm/d\",\n",
    "        \"Q\": \"mm/d\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5200f2db-a380-45bb-b7ac-11fdaf5de8fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not load:    \n",
    "    data_vars = {}\n",
    "    for i, name in enumerate(param_names + stor_names+ [\"Q\"]):\n",
    "        storage_terms_i = xr.DataArray(state_vector_arr[:,:,i].T,\n",
    "                                       name=name,\n",
    "                                       dims=[\"EnsembleMember\",\"time\"],\n",
    "                                      coords=[np.arange(n_particles),df_ensemble.index],\n",
    "                                      attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                               \"history\": f\"Storage term results from ewatercycle_HBV.model\",\n",
    "                                            \"description\":\"Moddeled values\",\n",
    "                                                 \"units\": \"mm\"})\n",
    "        data_vars[name] = storage_terms_i\n",
    "\n",
    "    ds_combined = xr.Dataset(data_vars,\n",
    "                             attrs={\"title\": f\"HBV storage terms data over time for {n_particles} particles \", \n",
    "                                    \"history\": f\"Storage term results from ewatercycle_HBV.model\",}\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c763f02-2dd7-4935-8dbd-b487de49e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save? \n",
    "if save:\n",
    "    ds_combined.to_netcdf(output_path / f'combined_ds_{current_time}.nc')\n",
    "    \n",
    "if load:\n",
    "    # ds_combined = xr.open_dataset(glob.glob(str(output_path / 'combined_ds_*.nc'))[-1])\n",
    "    ds_combined = xr.open_dataset(glob.glob(str(output_path / 'combined_ds_2024-04-03*.nc'))[0])\n",
    "    time = ds_combined.time.values\n",
    "    n_particles = len(ds_combined.EnsembleMember)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d1e02-3183-4bb5-b68a-e34c1404cd47",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cbb6af-8a63-4b97-8e0d-503f1f9c53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble.plot()\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "# ax.plot(ds.time.values[:n_days],ds['Q'].values[:n_days],lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color=\"k\")\n",
    "# ax.plot(df.index, Q_m_in_ref[1:],label=\"Modelled reference Q\");\n",
    "ds_obs['Q'].sel(time=time).plot(ax=ax,lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color='k')\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "df_ensemble.plot(ax=ax,alpha=0.5,zorder=-1,legend=False)\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "# ax.set_xlim((pd.Timestamp('2004-08-01'),pd.Timestamp('2005-12-01')))\n",
    "# ax.set_xlim((pd.Timestamp('1998-08-01'),pd.Timestamp('2001-12-01')))\n",
    "# ax.set_ylim((0,10))\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for_{n_particles}_particles_{current_time}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95eea2b-5327-4cb7-8878-394931769967",
   "metadata": {},
   "source": [
    "Can calculate the mea as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0d047-98c5-4dc6-accc-779dd4df1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_NSE(Qo, Qm):\n",
    "    QoAv  = np.mean(Qo)\n",
    "    ErrUp = np.sum((Qm - Qo)**2)\n",
    "    ErrDo = np.sum((Qo - QoAv)**2)\n",
    "    return 1 - (ErrUp / ErrDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf082d-2c2f-43f8-8e3b-989067410237",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ensemble = df_ensemble.T.mean()\n",
    "NSE_mean_ens = calc_NSE(ds_obs['Q'].sel(time=time).values,mean_ensemble.loc[time])\n",
    "NSE_mean_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7840c2fc-98b5-4718-95b7-d929f3466f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble.plot()\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "# ax.plot(ds.time.values[:n_days],ds['Q'].values[:n_days],lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color=\"k\")\n",
    "# ax.plot(df.index, Q_m_in_ref[1:],label=\"Modelled reference Q\");\n",
    "ds_obs['Q'].sel(time=time).plot(ax=ax,lw=0,marker=\"*\",ms=2.0,zorder=0,label=\"Observations\",color='k')\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"NSe mean {NSE_mean_ens:.2f}\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.35,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "# ax.set_xlim((pd.Timestamp('2000-08-01'),pd.Timestamp('2004-06-01')))\n",
    "# ax.set_xlim((pd.Timestamp('2004-08-01'),pd.Timestamp('2005-12-01')))\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for_{n_particles}_particles_{current_time}.png\",bbox_inches=\"tight\",dpi=400);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb853571-7b34-4019-8936-18d8ea1ee0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble.plot()\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "# ax.plot(ds.time.values[:n_days],ds['Q'].values[:n_days],lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color=\"k\")\n",
    "# ax.plot(df.index, Q_m_in_ref[1:],label=\"Modelled reference Q\");\n",
    "ds_obs['Q'].sel(time=time).plot(ax=ax,lw=0,marker=\"*\",ms=2.0,zorder=0,label=\"Observations\",color='k')\n",
    "\n",
    "ax_pr = ax.twinx()\n",
    "ax_pr.invert_yaxis()\n",
    "ax_pr.set_ylabel(f\"P [mm]\")\n",
    "ax_pr.bar(df_ensemble.index,ds['pr'].values[:len(time)],zorder=-15,label=\"Precipitation\",color=\"grey\")\n",
    "ax_pr.legend(bbox_to_anchor=(1.25,0.8))\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.35,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for_{n_particles}_particles_bounds_P_{current_time}.png\",bbox_inches=\"tight\",dpi=400);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf10705-d68d-4c87-8412-8600bb7a5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=6\n",
    "fig, axs = plt.subplots(n,1,figsize=(12,n*2),sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "ds_obs['Q'].sel(time=time).plot(ax=ax,lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color='k')\n",
    "ax_pr = ax.twinx()\n",
    "ax_pr.invert_yaxis()\n",
    "ax_pr.set_ylabel(f\"P [mm]\")\n",
    "# ax_pr.bar(df_ensemble.index,ds['pr'].values[:len(time)],zorder=-10,label=\"Precipitation\",color=\"grey\")\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.5,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "\n",
    "for i, S_name in enumerate(S_names):\n",
    "    for j in range(n_particles):\n",
    "        ds_combined[stor_names[i]].isel(EnsembleMember=j).plot(ax=axs[i+1],color=f\"C{i}\",alpha=0.5)\n",
    "        axs[i+1].set_title(S_name)\n",
    "        axs[i+1].set_ylabel(f'{stor_names[i]} [{units[stor_names[i]]}]')\n",
    "\n",
    "# remove all unncecearry xlabels\n",
    "[ax.set_xlabel(None) for ax in axs[:-1]]\n",
    "# [ax.set_ylabel(\"S [mm]\") for ax in axs[1:]]\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for__{n_particles}_particles_storages_{current_time}.png\",bbox_inches=\"tight\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a11c3-a3b6-456e-8ca7-f97feb2f9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3,figsize=(25,10),sharex=True)\n",
    "axs = axs.flatten()\n",
    "for j, parameter in enumerate(param_names):\n",
    "    ax = axs[j]\n",
    "    for i in range(n_particles):\n",
    "        ds_combined[parameter].isel(EnsembleMember=i).plot(ax=ax,alpha=0.3)\n",
    "    ax.set_title(f'parameter={parameter}')# for {n_particles} Ensemble Members')\n",
    "    ax.set_ylabel(f'[{units[param_names[j]]}]')\n",
    "if save:\n",
    "    fig.savefig(figure_path /  f\"ensemble_run_for__{n_particles}_particles_parameters_{current_time}.png\",bbox_inches=\"tight\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701a927-b500-4f52-9ace-1f7de3cd5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names_0 = param_names[:4]\n",
    "param_names_1 = param_names[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ca32e-1887-4e72-afcd-f69d6c112421",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "fig, axs = plt.subplots(n,1,figsize=(12,n*2),sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "ds_obs['Q'].sel(time=time).plot(ax=ax,lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color='k')\n",
    "ax_pr = ax.twinx()\n",
    "ax_pr.invert_yaxis()\n",
    "ax_pr.set_ylabel(f\"P [mm]\")\n",
    "# ax_pr.bar(df_ensemble.index,ds['pr'].values[:len(time)],zorder=-10,label=\"Precipitation\",color=\"grey\")\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.5,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "\n",
    "\n",
    "for i, parameter in enumerate(param_names_0):\n",
    "    for j in range(n_particles):\n",
    "        ds_combined[parameter].isel(EnsembleMember=j).plot(ax=axs[i+1],color=f\"C{i}\",alpha=0.5)\n",
    "        axs[i+1].set_title(parameter)\n",
    "        axs[i+1].set_ylabel(f'{param_names_0[i]} [{units[param_names_0[i]]}]')\n",
    "\n",
    "# remove all unncecearry xlabels\n",
    "[ax.set_xlabel(None) for ax in axs[:-1]]\n",
    "# [ax.set_ylabel(\"S [mm]\") for ax in axs[1:]]\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for__{n_particles}_particles_storages_{current_time}.png\",bbox_inches=\"tight\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06dd6d7-2728-4926-95c3-30651306acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=6\n",
    "fig, axs = plt.subplots(n,1,figsize=(12,n*2),sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "ds_obs['Q'].sel(time=time).plot(ax=ax,lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color='k')\n",
    "ax_pr = ax.twinx()\n",
    "ax_pr.invert_yaxis()\n",
    "ax_pr.set_ylabel(f\"P [mm]\")\n",
    "# ax_pr.bar(df_ensemble.index,ds['pr'].values[:len(time)],zorder=-10,label=\"Precipitation\",color=\"grey\")\n",
    "\n",
    "ax.plot(mean_ensemble,color=\"C1\",lw=0.5,label=f\"mean\",zorder=-1)\n",
    "ax.fill_between(df_ensemble.index,df_ensemble.T.min(),df_ensemble.T.max(),color=\"C0\", alpha=0.5,zorder=-10,label=\"bounds\")\n",
    "ax.legend(bbox_to_anchor=(1.25,1))\n",
    "ax.set_ylabel(\"Q [mm]\")\n",
    "\n",
    "ax.set_title(f\"Run ensemble of {n_particles} particles\");\n",
    "\n",
    "\n",
    "for i, parameter in enumerate(param_names_1):\n",
    "    for j in range(n_particles):\n",
    "        ds_combined[parameter].isel(EnsembleMember=j).plot(ax=axs[i+1],color=f\"C{i}\",alpha=0.5)\n",
    "        axs[i+1].set_title(parameter)\n",
    "        axs[i+1].set_ylabel(f'{param_names_1[i]} [{units[param_names_1[i]]}]')\n",
    "# remove all unncecearry xlabels\n",
    "[ax.set_xlabel(None) for ax in axs[:-1]]\n",
    "# [ax.set_ylabel(\"S [mm]\") for ax in axs[1:]]\n",
    "if save:\n",
    "    fig.savefig(figure_path / f\"ensemble_run_for__{n_particles}_particles_storages_{current_time}.png\",bbox_inches=\"tight\",dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6461afd8-181b-4e52-8ed3-551e188b3962",
   "metadata": {},
   "source": [
    "# analyse posterio & prior "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c68885-c2ca-4510-b18a-e8e8588c9b3a",
   "metadata": {},
   "source": [
    "good :105, 500, 1000 ,<br>\n",
    "bad: > 1350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b78df6-f529-483d-958d-bcdcd0996fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3\n",
    "n = 14\n",
    "offset = 102\n",
    "selected_time = time[offset:offset+m*n]\n",
    "resample = np.array([time if index%3==0 else None for index, time in enumerate(selected_time)])\n",
    "resample = resample[~(resample == None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d28932-17e4-4095-9f00-9feb3b4b25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,5))\n",
    "ds_obs['Q'].sel(time=selected_time).plot(ax=ax, lw=0,marker=\"*\",ms=2.5,zorder=0,label=\"Observations\",color='k')\n",
    "ds_obs['Q'].sel(time=resample).plot(ax=ax, lw=0,marker=\"*\",ms=5,zorder=0,label=\"Resample steps\",color='r')\n",
    "ax.fill_between(df_ensemble.loc[selected_time].index,df_ensemble.loc[selected_time].T.min(),df_ensemble.loc[selected_time].T.max(),color=\"C0\", alpha=0.5,zorder=-10,label=\"bounds\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992d111-a057-42ab-8642-9b517bb6ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,n//2, figsize=(23,5))\n",
    "axs = axs.flatten()\n",
    "counter=0\n",
    "for index, i in enumerate(range(offset, offset+ (m * n))):\n",
    "    if i % 3 == 0:\n",
    "        ax = axs[index//3]\n",
    "        # ds_combined_prior[\"Q\"].sel(time=time[i]).plot.hist(ax=ax,density=True, color=\"C1\",zorder=-1,alpha=0.5,label=\"Prior (i)\");\n",
    "        ax.hist(df_ensemble_prior.loc[time[i]],density=True,color=\"C0\",zorder=1,alpha=0.5,label=\"Prior\");\n",
    "        ax.hist(df_ensemble.loc[time[i]],density=True,color=\"C1\",zorder=1,alpha=0.5,label=\"Posterior\");\n",
    "        \n",
    "        ax.axvline(ds_obs[\"Q\"].sel(time=time[i-1], method=\"nearest\").values,color=\"grey\",ls=\"--\", label=\"Qi-1\")\n",
    "        ax.axvline(ds_obs[\"Q\"].sel(time=time[i], method=\"nearest\").values,color=\"k\", label=\"Q\")\n",
    "        ax.axvline(ds_obs[\"Q\"].sel(time=time[i+1], method=\"nearest\").values,color=\"grey\", label=\"Qi+1\")\n",
    "        \n",
    "        ax.set_title(f\"day={i}\")\n",
    "        if counter == 0:\n",
    "            ax.legend(bbox_to_anchor=(-0.23,1.05))\n",
    "            ax.set_xlabel(\"Q [mm]\")\n",
    "            ax.set_ylabel(\"Probability density\")\n",
    "            counter+=1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba551fe-3a41-4dde-8231-44641378e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3,figsize=(25,10),sharex=True)\n",
    "axs = axs.flatten()\n",
    "for j, parameter in enumerate(param_names):\n",
    "    ax = axs[j]\n",
    "    for i in range(n_particles):\n",
    "        ds_combined[parameter].isel(EnsembleMember=i).sel(time=selected_time).plot(ax=ax,alpha=0.3)\n",
    "    ax.set_title(f'parameter={parameter}')# for {n_particles} Ensemble Members')\n",
    "    ax.set_ylabel(f'[{units[param_names[j]]}]')\n",
    "if save:\n",
    "    fig.savefig(figure_path /  f\"ensemble_run_for__{n_particles}_particles_parameters_{current_time}.png\",bbox_inches=\"tight\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208cf713-e9eb-4a7d-8b0c-eda302ddb907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3f080-8f7d-4b60-a88b-409b9dbe5e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
